{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "import importlib.util\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'runs/Jul24_21-14-05_WMII2084'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michalgorszczak/miniconda3/envs/simclr/lib/python3.7/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 30,\n",
       " 'epochs': 10,\n",
       " 'eval_every_n_epochs': 1,\n",
       " 'fine_tune_from': 'None',\n",
       " 'log_every_n_steps': 50,\n",
       " 'weight_decay': '10e-6',\n",
       " 'fp16_precision': False,\n",
       " 'model': {'out_dim': 256, 'base_model': 'resnet50'},\n",
       " 'dataset': {'s': 1,\n",
       "  'input_shape': '(240,320,3)',\n",
       "  'num_workers': 0,\n",
       "  'valid_size': 0.05},\n",
       " 'loss': {'temperature': 0.5, 'use_cosine_similarity': True}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints_folder = os.path.join(folder_name, 'checkpoints')\n",
    "config = yaml.load(open(os.path.join(checkpoints_folder, \"config.yaml\"), \"r\"))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neural net module\n",
    "spec = importlib.util.spec_from_file_location(\"model\", 'models/resnet_simclr.py')\n",
    "resnet_module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(resnet_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extractor: resnet50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet_module.ResNetSimCLR(**config['model'])\n",
    "model.eval()\n",
    "\n",
    "state_dict = torch.load(os.path.join(checkpoints_folder, 'model.pth'), map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimCLRTrasfer(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(SimCLRTrasfer, self).__init__()\n",
    "        self.pretrained_model = pretrained_model\n",
    "\n",
    "        \n",
    "        self.features = nn.Sequential(*list(self.pretrained_model.children())[:-2])\n",
    "\n",
    "        # projection MLP\n",
    "        self.l1 = nn.Linear(2048, 1000)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.features(x)\n",
    "        h = h.squeeze()\n",
    "\n",
    "        x = self.l1(h)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = SimCLRTrasfer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_PATH = \"/media/data2/infotech/datasets/imagenet/\"\n",
    "TRAIN_FOLDER_NAME = \"train\"\n",
    "VALIDATION_FOLDER_NAME = \"val\"\n",
    "\n",
    "LIST_OF_FOLDERS_SLASH_CLASSES = os.listdir(os.path.join(IMAGENET_PATH, TRAIN_FOLDER_NAME))\n",
    "\n",
    "\n",
    "def extract_images_and_their_classes(train_or_val):   \n",
    "    list_of_images_paths = { x: os.listdir(os.path.join(IMAGENET_PATH, train_or_val, x))\n",
    "    for x in LIST_OF_FOLDERS_SLASH_CLASSES}\n",
    "\n",
    "    this_is_going_out = np.array( [(z, x)  for x, y \n",
    "    in list_of_images_paths.items() for z in y] )\n",
    "\n",
    "    shake_it = np.random.permutation(this_is_going_out.shape[0])\n",
    "\n",
    "    return this_is_going_out[shake_it]\n",
    "\n",
    "\n",
    "def generator(b_s, phase_gen='train'):\n",
    "    def add_path_information(image_and_class):\n",
    "        return np.array(os.path.join(IMAGENET_PATH, phase_gen, image_and_class[1], image_and_class[0]), dtype=object)\n",
    "    \n",
    "    images_and_their_classes = extract_images_and_their_classes(phase_gen).astype(object)\n",
    "   \n",
    "    counter = 0\n",
    "    while True:\n",
    "        images = np.apply_along_axis(add_path_information, axis=1, \n",
    "        arr=images_and_their_classes[counter:counter + b_s])\n",
    "\n",
    "        y = enc.transform(images_and_their_classes[counter:counter + b_s, 1].reshape(-1, 1)).toarray()\n",
    "        \n",
    "        yield preprocess_images(images, shape_r, shape_c), y\n",
    "        counter = (counter + b_s) % images_and_their_classes.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "class ImagenetDataset(Dataset):\n",
    "    def __init__(self, dataset_part:str, labels_part:float = 1., transform = None):\n",
    "        self.__transforms = transform\n",
    "        self.__imagenet_path = \"/media/data2/infotech/datasets/imagenet/\"\n",
    "        self.__LIST_OF_FOLDERS_SLASH_CLASSES = np.array( os.listdir(\n",
    "            os.path.join(IMAGENET_PATH, dataset_part)))\n",
    "        self.__dataset_part = dataset_part\n",
    "        list_of_images_paths = { x: np.array(os.listdir(os.path\n",
    "                                               .join(self.__imagenet_path, dataset_part, x)))\n",
    "                                [:int (len(os.listdir(os.path\n",
    "                                               .join(self.__imagenet_path, dataset_part, x)))\n",
    "                                       * labels_part)]\n",
    "                                for x in self.__LIST_OF_FOLDERS_SLASH_CLASSES}\n",
    "\n",
    "        this_is_going_out = np.array( [(z, x)  for x, y\n",
    "                                       in list_of_images_paths.items() for z in y] )\n",
    "\n",
    "        shake_it = np.random.permutation(this_is_going_out.shape[0])\n",
    "        \n",
    "        self.__images = this_is_going_out[shake_it]\n",
    "        \n",
    "        self.enc = preprocessing.OneHotEncoder()\n",
    "        self.enc.fit(self.__LIST_OF_FOLDERS_SLASH_CLASSES.reshape(-1,1))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.__images.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        to_work_on = self.__images[idx]\n",
    "        \n",
    "        path_to_image = os.path.join(self.__imagenet_path, self.__dataset_part, \n",
    "                                     to_work_on[1], to_work_on[0]) \n",
    "        image = Image.open(path_to_image).convert('RGB')\n",
    "        one_hot = self.enc.transform(to_work_on[1].reshape(-1, 1)).toarray()\n",
    "        \n",
    "        one_hot = np.where(one_hot==1)[1][0]\n",
    "        \n",
    "        \n",
    "        if self.__transforms is not None:\n",
    "            image = self.__transforms(image)\n",
    "        \n",
    "        return image, torch.tensor(one_hot, dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize( (224,224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "optimizer = torch.optim.Adam(transfer_model.parameters(), 3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataset = ImagenetDataset(\"train\", .1, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, drop_last=True, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize( (224,224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "optimizer = torch.optim.SGD(transfer_model.parameters(), lr=0.05 * batch_size / 256, momentum=0.9, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataset = ImagenetDataset(\"train\", .1, transform=transform)\n",
    "val_dataset = ImagenetDataset(\"val\", .1, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = transfer_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, data_loader, criterion):\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "        \n",
    "        top_five_answer = 0\n",
    "        top_one_anwer = 0\n",
    "        valid_loss = 0.0\n",
    "        counter = 0\n",
    "        \n",
    "        for inputs, labels in data_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                model_resoult = model(inputs)\n",
    "                loss = criterion(model_resoult, labels)\n",
    "                \n",
    "                valid_loss += loss.item()\n",
    "                counter += 1\n",
    "                \n",
    "                model_resoult, indices = torch.sort(model_resoult, dim=1, descending=True)\n",
    "\n",
    "                indices = indices[:, :5]\n",
    "\n",
    "                resoult = indices == labels.reshape(-1, 1)\n",
    "                resoult_top_one =  indices[:,0] == labels\n",
    "                top_five_answer += torch.sum(resoult)\n",
    "                top_one_anwer += torch.sum(resoult_top_one)\n",
    "        valid_loss /= counter\n",
    "    model.train()\n",
    "    return (top_five_answer.float() / (batch_size * len(val_loader)) * 100, \n",
    "            top_one_anwer.float() / (batch_size * len(val_loader)) * 100,\n",
    "           valid_loss)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate( model, valid_loader, criterion):\n",
    "\n",
    "    # validation steps\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        valid_loss = 0.0\n",
    "        counter = 0\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            model_resoult = model(inputs)\n",
    "            loss = criterion(model_resoult, labels)\n",
    "            \n",
    "            valid_loss += loss.item()\n",
    "            counter += 1\n",
    "        valid_loss /= counter\n",
    "    model.train()\n",
    "    return valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1,    20] loss: 7.234\n",
      "[1,    40] loss: 7.086\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "best_valid_loss = np.inf\n",
    "tensorboard_writer = SummaryWriter()\n",
    "os.makedirs(os.path.join(tensorboard_writer.log_dir, 'checkpoints'))\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    print(epoch)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "#         print(i)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = transfer_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            tensorboard_writer.add_scalar(\"Loss/train\", running_loss / 20, global_step=n_iter)\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0            \n",
    "    \n",
    "        n_iter += 1\n",
    "        \n",
    "    top_five, top_one, valid_loss = check_accuracy(transfer_model, val_loader, criterion)\n",
    "    tensorboard_writer.add_scalar(\"Acc/val/top_five\", top_five, epoch)\n",
    "    tensorboard_writer.add_scalar(\"Acc/val/top_one\", top_one, epoch)\n",
    "    \n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(transfer_model.state_dict(),  os.path.join(tensorboard_writer.log_dir, 'checkpoints', 'model.pth'))\n",
    "        \n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
